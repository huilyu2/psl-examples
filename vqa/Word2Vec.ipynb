{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, os  \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)  \n",
    "  \n",
    "import nltk  \n",
    "from nltk.corpus import brown, movie_reviews, treebank\n",
    "corpus = brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-21 10:14:06,729 : INFO : loading Word2Vec object from brown_skipgram.model\n",
      "2018-06-21 10:14:06,876 : INFO : loading wv recursively from brown_skipgram.model.wv.* with mmap=None\n",
      "2018-06-21 10:14:06,877 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-06-21 10:14:06,878 : INFO : loading vocabulary recursively from brown_skipgram.model.vocabulary.* with mmap=None\n",
      "2018-06-21 10:14:06,878 : INFO : loading trainables recursively from brown_skipgram.model.trainables.* with mmap=None\n",
      "2018-06-21 10:14:06,879 : INFO : setting ignored attribute cum_table to None\n",
      "2018-06-21 10:14:06,880 : INFO : loaded brown_skipgram.model\n"
     ]
    }
   ],
   "source": [
    "fname = 'brown_skipgram.model'  \n",
    "if os.path.exists(fname):  \n",
    "    # load the file if it has already been trained, to save repeating the slow training step below  \n",
    "    model = gensim.models.Word2Vec.load(fname)  \n",
    "else:  \n",
    "    # can take a few minutes, grab a cuppa  \n",
    "    model = gensim.models.Word2Vec(corpus, size=100, min_count=5, workers=2, iter=50)   \n",
    "    model.save(fname)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse horse 1.0\n",
      "horse barn 0.32499087867130183\n",
      "horse church 0.19455762502706284\n",
      "horse fence 0.3485812494105681\n",
      "horse tree 0.25745871781519\n",
      "horse building 0.05488356081858706\n",
      "horse background -0.0021641229785151553\n",
      "horse hotel 0.22747970321724675\n",
      "horse in -0.05262146685371784\n",
      "horse is -0.25475306300475514\n",
      "horse color 0.029466336324977034\n",
      "horse grey 0.07331464688233767\n",
      "horse behind 0.22414768959252807\n",
      "barn horse 0.32499087867130183\n",
      "barn barn 0.9999999999999999\n",
      "barn church 0.12043223081598908\n",
      "barn fence 0.5768948773238054\n",
      "barn tree 0.388676357787483\n",
      "barn building 0.2882358892220665\n",
      "barn background -0.03608052423298633\n",
      "barn hotel 0.30350682032633913\n",
      "barn in -0.12016775020099527\n",
      "barn is -0.17665657087635822\n",
      "barn color 0.05147154772942686\n",
      "barn grey 0.25764990408288957\n",
      "barn behind 0.14193280911250136\n",
      "church horse 0.19455762502706284\n",
      "church barn 0.12043223081598908\n",
      "church church 1.0\n",
      "church fence 0.03428438688864162\n",
      "church tree 0.05256823662859336\n",
      "church building 0.27783003584400784\n",
      "church background 0.18127397463745995\n",
      "church hotel 0.38150653374703647\n",
      "church in -0.003807851240455542\n",
      "church is -0.03522343633954317\n",
      "church color 0.08628623263791146\n",
      "church grey 0.08494059569792696\n",
      "church behind 0.08021579532416606\n",
      "fence horse 0.3485812494105681\n",
      "fence barn 0.5768948773238054\n",
      "fence church 0.03428438688864162\n",
      "fence fence 1.0\n",
      "fence tree 0.45511678834113833\n",
      "fence building 0.3149780450632469\n",
      "fence background 0.003143128231143065\n",
      "fence hotel 0.1683777999425178\n",
      "fence in -0.030481691816003277\n",
      "fence is -0.07952158025002773\n",
      "fence color 0.03938881500672753\n",
      "fence grey 0.30864879491539254\n",
      "fence behind 0.2852174398169208\n",
      "tree horse 0.25745871781519\n",
      "tree barn 0.388676357787483\n",
      "tree church 0.05256823662859336\n",
      "tree fence 0.45511678834113833\n",
      "tree tree 1.0\n",
      "tree building 0.24650579097310427\n",
      "tree background 0.17628892907900884\n",
      "tree hotel 0.29285771797271226\n",
      "tree in -0.08523759356563826\n",
      "tree is -0.019524825512350054\n",
      "tree color 0.38338184849864365\n",
      "tree grey 0.31923834894865066\n",
      "tree behind 0.3085241840296683\n",
      "building horse 0.05488356081858706\n",
      "building barn 0.2882358892220665\n",
      "building church 0.27783003584400784\n",
      "building fence 0.3149780450632469\n",
      "building tree 0.24650579097310427\n",
      "building building 1.0\n",
      "building background 0.15106938777787932\n",
      "building hotel 0.22970371939399387\n",
      "building in 0.16358860370813352\n",
      "building is -0.008824449254613162\n",
      "building color 0.16374210106877735\n",
      "building grey 0.192078829937867\n",
      "building behind 0.10217159082640162\n",
      "background horse -0.0021641229785151553\n",
      "background barn -0.03608052423298633\n",
      "background church 0.18127397463745995\n",
      "background fence 0.003143128231143065\n",
      "background tree 0.17628892907900884\n",
      "background building 0.15106938777787932\n",
      "background background 1.0000000000000002\n",
      "background hotel 0.03394646363594933\n",
      "background in 0.09829033378980552\n",
      "background is 0.1382023502526407\n",
      "background color 0.38177992210128453\n",
      "background grey 0.23208205649033165\n",
      "background behind 0.03947815426706466\n",
      "hotel horse 0.22747970321724675\n",
      "hotel barn 0.30350682032633913\n",
      "hotel church 0.38150653374703647\n",
      "hotel fence 0.1683777999425178\n",
      "hotel tree 0.29285771797271226\n",
      "hotel building 0.22970371939399387\n",
      "hotel background 0.03394646363594933\n",
      "hotel hotel 1.0\n",
      "hotel in -0.002725329954031644\n",
      "hotel is -0.20346021530683736\n",
      "hotel color 0.05209074144001036\n",
      "hotel grey 0.2168077744527398\n",
      "hotel behind 0.08439586735650043\n",
      "in horse -0.05262146685371784\n",
      "in barn -0.12016775020099527\n",
      "in church -0.003807851240455542\n",
      "in fence -0.030481691816003277\n",
      "in tree -0.08523759356563826\n",
      "in building 0.16358860370813352\n",
      "in background 0.09829033378980552\n",
      "in hotel -0.002725329954031644\n",
      "in in 0.9999999999999999\n",
      "in is -0.10389867358151668\n",
      "in color 0.07725847195003938\n",
      "in grey -0.00830236706474713\n",
      "in behind 0.1709494549223146\n",
      "is horse -0.25475306300475514\n",
      "is barn -0.17665657087635822\n",
      "is church -0.03522343633954317\n",
      "is fence -0.07952158025002773\n",
      "is tree -0.019524825512350054\n",
      "is building -0.008824449254613162\n",
      "is background 0.1382023502526407\n",
      "is hotel -0.20346021530683736\n",
      "is in -0.10389867358151668\n",
      "is is 1.0\n",
      "is color 7.71031881237165e-05\n",
      "is grey -0.20489806258156332\n",
      "is behind -0.15555810680320467\n",
      "color horse 0.029466336324977034\n",
      "color barn 0.05147154772942686\n",
      "color church 0.08628623263791146\n",
      "color fence 0.03938881500672753\n",
      "color tree 0.38338184849864365\n",
      "color building 0.16374210106877735\n",
      "color background 0.38177992210128453\n",
      "color hotel 0.05209074144001036\n",
      "color in 0.07725847195003938\n",
      "color is 7.71031881237165e-05\n",
      "color color 1.0\n",
      "color grey 0.3111048629895417\n",
      "color behind 0.07725594099731994\n",
      "grey horse 0.07331464688233767\n",
      "grey barn 0.25764990408288957\n",
      "grey church 0.08494059569792696\n",
      "grey fence 0.30864879491539254\n",
      "grey tree 0.31923834894865066\n",
      "grey building 0.192078829937867\n",
      "grey background 0.23208205649033165\n",
      "grey hotel 0.2168077744527398\n",
      "grey in -0.00830236706474713\n",
      "grey is -0.20489806258156332\n",
      "grey color 0.3111048629895417\n",
      "grey grey 0.9999999999999998\n",
      "grey behind 0.11421245714946662\n",
      "behind horse 0.22414768959252807\n",
      "behind barn 0.14193280911250136\n",
      "behind church 0.08021579532416606\n",
      "behind fence 0.2852174398169208\n",
      "behind tree 0.3085241840296683\n",
      "behind building 0.10217159082640162\n",
      "behind background 0.03947815426706466\n",
      "behind hotel 0.08439586735650043\n",
      "behind in 0.1709494549223146\n",
      "behind is -0.15555810680320467\n",
      "behind color 0.07725594099731994\n",
      "behind grey 0.11421245714946662\n",
      "behind behind 1.0\n"
     ]
    }
   ],
   "source": [
    "words = \"horse barn church fence tree building background hotel in is color grey behind\".split()  \n",
    "for w1 in words:  \n",
    "    for w2 in words:  \n",
    "        print(w1, w2, model.wv.similarity(w1, w2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.71031881237165e-05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"is\", \"color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example for training Word2Vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-21 10:14:07,110 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to /Users/huilyu/nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/huilyu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-21 10:14:07,121 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-06-21 10:14:07,834 : INFO : PROGRESS: at sentence #10000, processed 266283 words, keeping 15327 word types\n",
      "2018-06-21 10:14:08,489 : INFO : PROGRESS: at sentence #20000, processed 530624 words, keeping 25441 word types\n",
      "2018-06-21 10:14:09,066 : INFO : collected 31885 word types from a corpus of 766811 raw words and 29059 sentences\n",
      "2018-06-21 10:14:09,067 : INFO : Loading a fresh vocabulary\n",
      "2018-06-21 10:14:09,097 : INFO : min_count=5 retains 10363 unique words (32% of original 31885, drops 21522)\n",
      "2018-06-21 10:14:09,098 : INFO : min_count=5 leaves 730000 word corpus (95% of original 766811, drops 36811)\n",
      "2018-06-21 10:14:09,128 : INFO : deleting the raw counts dictionary of 31885 items\n",
      "2018-06-21 10:14:09,130 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2018-06-21 10:14:09,131 : INFO : downsampling leaves estimated 540590 word corpus (74.1% of prior 730000)\n",
      "2018-06-21 10:14:09,160 : INFO : estimated required memory for 10363 words and 100 dimensions: 13471900 bytes\n",
      "2018-06-21 10:14:09,160 : INFO : resetting layer weights\n",
      "2018-06-21 10:14:09,269 : INFO : training model with 3 workers on 10363 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-06-21 10:14:10,277 : INFO : EPOCH 1 - PROGRESS: at 46.55% examples, 256859 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:11,294 : INFO : EPOCH 1 - PROGRESS: at 97.58% examples, 261010 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:11,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-21 10:14:11,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-21 10:14:11,355 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-21 10:14:11,356 : INFO : EPOCH - 1 : training on 766811 raw words (540516 effective words) took 2.1s, 259171 effective words/s\n",
      "2018-06-21 10:14:12,379 : INFO : EPOCH 2 - PROGRESS: at 45.27% examples, 247139 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:13,397 : INFO : EPOCH 2 - PROGRESS: at 96.24% examples, 256040 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:13,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-21 10:14:13,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-21 10:14:13,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-21 10:14:13,470 : INFO : EPOCH - 2 : training on 766811 raw words (540585 effective words) took 2.1s, 256424 effective words/s\n",
      "2018-06-21 10:14:14,503 : INFO : EPOCH 3 - PROGRESS: at 47.88% examples, 258752 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:15,526 : INFO : EPOCH 3 - PROGRESS: at 98.90% examples, 261304 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:15,536 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-21 10:14:15,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-21 10:14:15,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-21 10:14:15,549 : INFO : EPOCH - 3 : training on 766811 raw words (540438 effective words) took 2.1s, 260958 effective words/s\n",
      "2018-06-21 10:14:16,571 : INFO : EPOCH 4 - PROGRESS: at 47.88% examples, 260061 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:17,564 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-21 10:14:17,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-21 10:14:17,573 : INFO : EPOCH 4 - PROGRESS: at 100.00% examples, 267202 words/s, in_qsize 0, out_qsize 1\n",
      "2018-06-21 10:14:17,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-21 10:14:17,576 : INFO : EPOCH - 4 : training on 766811 raw words (540290 effective words) took 2.0s, 266871 effective words/s\n",
      "2018-06-21 10:14:18,599 : INFO : EPOCH 5 - PROGRESS: at 49.19% examples, 267383 words/s, in_qsize 0, out_qsize 0\n",
      "2018-06-21 10:14:19,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-21 10:14:19,567 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-21 10:14:19,577 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-21 10:14:19,577 : INFO : EPOCH - 5 : training on 766811 raw words (540500 effective words) took 2.0s, 270824 effective words/s\n",
      "2018-06-21 10:14:19,578 : INFO : training on a 3834055 raw words (2702329 effective words) took 10.3s, 262145 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#from gensim.corpora import WikiCorpus\n",
    "import nltk\n",
    "nltk.download('abc')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import abc\n",
    "b = Word2Vec(abc.sents())\n",
    "# mr = Word2Vec(movie_reviews.sents())\n",
    "# t = Word2Vec(treebank.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huilyu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-06-21 10:14:19,587 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('information', 0.9287192821502686),\n",
       " ('put', 0.9198907613754272),\n",
       " ('difficult', 0.9064333438873291),\n",
       " ('us', 0.8973759412765503),\n",
       " ('themselves', 0.892667293548584)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huilyu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Cattle', 0.9784817099571228),\n",
       " ('pear', 0.9743441343307495),\n",
       " ('chicken', 0.9670129418373108),\n",
       " ('fishermen', 0.962110161781311),\n",
       " ('Kangaroo', 0.9618431925773621),\n",
       " ('Table', 0.9606196284294128),\n",
       " ('Quarantine', 0.9605086445808411),\n",
       " ('banana', 0.9605034589767456),\n",
       " ('Desert', 0.9591423869132996),\n",
       " ('Eastern', 0.9587815999984741),\n",
       " ('Eight', 0.9577393531799316),\n",
       " ('Sheep', 0.9569904208183289),\n",
       " ('cherry', 0.9564056396484375),\n",
       " ('Grain', 0.9560607075691223),\n",
       " ('beekeepers', 0.9554308652877808),\n",
       " ('representatives', 0.9554122686386108),\n",
       " ('lamb', 0.9552083015441895),\n",
       " ('Fruit', 0.9542449712753296),\n",
       " ('NT', 0.9540547132492065),\n",
       " ('City', 0.953415036201477)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.most_similar('apple', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huilyu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ionosphere', 0.9625688195228577),\n",
       " ('Tokyo', 0.9618353247642517),\n",
       " ('Shakespeare', 0.9605059623718262),\n",
       " ('1983', 0.9519456624984741),\n",
       " ('heating', 0.9518120288848877),\n",
       " ('youth', 0.9511633515357971),\n",
       " ('rodeo', 0.9509605169296265),\n",
       " ('core', 0.9501490592956543),\n",
       " ('Greek', 0.9499202966690063),\n",
       " ('copper', 0.9494541883468628),\n",
       " ('bulls', 0.9493855237960815),\n",
       " ('Medal', 0.9492664337158203),\n",
       " ('Brunini', 0.9466891884803772),\n",
       " ('September', 0.9463322758674622),\n",
       " ('voters', 0.9454492926597595),\n",
       " ('mineral', 0.9454271793365479),\n",
       " ('workplace', 0.945389986038208),\n",
       " ('dried', 0.9452536702156067),\n",
       " ('feedlot', 0.9450489282608032),\n",
       " ('political', 0.9440691471099854)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.most_similar('strawberry', topn=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
